round(mean(train$Time) + 1.96*sd(boot_statistic),4))
#doing the boostrap:
replicate(1000, {
boot_sample <- sample(1:nrow(train), replace = TRUE)
mean(train$Time[boot_sample])
}) -> boot_statistic
hist(boot_statistic, breaks = 50)
sd(boot_statistic)
paste("The confidence interval is",
round(mean(train$Time) - 1.96*sd(boot_statistic),4),
round(mean(train$Time) + 1.96*sd(boot_statistic),4))
se <- sd(boot_statistic)
interval <- mean(train$Time) + c(1,-1)*2*se
paste("The confidence interval is", interval)
paste("The confidence interval is", interval)
interval <- mean(train$Time) + c(1,-1)*1.96*se
model <- lm(mpg ~ horspower, data = data)
model <- lm(mpg ~ horspower, data = mtcars)
model <- lm(mpg ~ horspower, data = Auto)
library(ISLR)
model <- lm(mpg ~ horspower, data = Auto)
data(Auto)
model <- lm(mpg ~ horspower, data = Auto)
View(Auto)
model <- lm(mpg ~ horspower, data = Auto)
model <- lm(mpg ~ horsepower, data = Auto)
model
summary()
summary(model)
plot(Auto$horsepower, Auto$mpg)
model$residuals
plot(model$residuals)
train(model$residuals)
plot(model$residuals)
model <- lm(mpg ~ horsepower + horsepower^2, data = Auto)
plot(model$residuals)
model <- lm(mpg ~ poly(horsepower,2), data = Auto)
plot(model$residuals)
model <- lm(mpg ~ poly(horsepower,4), data = Auto)
plot(model$residuals)
sumary(model)
summary(model)
model <- lm(mpg ~ poly(horsepower,10), data = Auto)
summary(model)
model <- lm(mpg ~ horsepower, data = Auto)
summary(model)
plot(Auto$horsepower, Auto$mpg)
model$fitted.values
model$coefficients
model$coefficients[1]
model$coefficients[2]
boot_sample <- resample(1:nrow(Auto), replace = TRUE)
boot_sample <- sample(1:nrow(Auto), replace = TRUE)
replicate(10,{
boot_sample <- sample(1:nrow(Auto), replace = TRUE)
data <- Auto[boot_sample,]
model <- lm(mpg ~ horsepower, data = data)
model$mpg ~ horsepower, data = Auto
} -> boot_estimate
replicate(10,{
boot_sample <- sample(1:nrow(Auto), replace = TRUE)
data <- Auto[boot_sample,]
model <- lm(mpg ~ horsepower, data = data)
model$mpg ~ horsepower, data = Auto
} -> boot_estimate
model$coefficients[2]
replicate(10,{
boot_sample <- sample(1:nrow(Auto), replace = TRUE)
data <- Auto[boot_sample,]
model <- lm(mpg ~ horsepower, data = data)
model$coefficients[2]
}
replicate(10,{
boot_sample <- sample(1:nrow(Auto), replace = TRUE)
data <- Auto[boot_sample,]
model <- lm(mpg ~ horsepower, data = data)
model$coefficients[2]
})
replicate(100,{
boot_sample <- sample(1:nrow(Auto), replace = TRUE)
data <- Auto[boot_sample,]
model <- lm(mpg ~ horsepower, data = data)
model$coefficients[2]
})
replicate(100,{
boot_sample <- sample(1:nrow(Auto), replace = TRUE)
data <- Auto[boot_sample,]
model <- lm(mpg ~ horsepower, data = data)
model$coefficients[2]
}) -> boot_statistic
hist(boot_statistic)
se <- sd(boot_statistic)
se <- sd(boot_statistic)
se
1.96*se
summary(model)
se
replicate(1000,{
boot_sample <- sample(1:nrow(Auto), replace = TRUE)
data <- Auto[boot_sample,]
model <- lm(mpg ~ horsepower, data = data)
model$coefficients[2]
}) -> boot_statistic
hist(boot_statistic)
se <- sd(boot_statistic)
se
model <- lm(mpg ~ horsepower, data = Auto)
summary(model)
interval <- mean(boot_statistic)
mean(boot_statistic)
interval <- mean(boot_statistic) + c(-2,2)*se
print(interval)
plot(model$residuals)
data(Boston)
library(ISLR)
data(Boston)
library(MASS)
data(Boston)
train <- Boston
View(Boston)
?Boston
mean(train$mdedv)
mean(train$medv)
t.test(train$medv)
data <- train$medv
data <- train$medv
replicate(1000 {
boot_samples <- sample(1:length(data), replace = TRUE)
mean(data[boot_samples])
}) -> boot_statistic
replicate(1000, {
boot_samples <- sample(1:length(data), replace = TRUE)
mean(data[boot_samples])
}) -> boot_statistic
interval <- mean(data) + c(-2,2)*sd(boot_statistic)
t.test(train$medv)
replicate(1000, {
boot_samples <- sample(1:length(data), replace = TRUE)
median(data[boot_samples])
}) -> boot_statistic
1.96*sd(boot_statistic)
quantile(data, .9)
hist(data)
replicate(1000, {
boot_samples <- sample(1:length(data), replace = TRUE)
quantile(data[boot_samples], .9)
}) -> boot_statistic
1.96*sd(boot_statistic)
bootstrap <- function(data, statistic, n = 1000) {
replicate(n, {
boot_samples <- sample(1:length(data), replace = TRUE)
statistic(boot_samples)
}) -> boot_statistic
}
boostrap(data, mean)
bootstrap(data, mean)
bootstrap <- function(data, statistic, n = 1000) {
replicate(n, {
boot_samples <- sample(1:length(data), replace = TRUE)
statistic(boot_samples)
}) -> boot_statistic
boot_statistic
}
bootstrap(data, mean)
mean(train$medv)
bootstrap <- function(data, statistic, n = 1000) {
replicate(n, {
boot_samples <- sample(1:length(data), replace = TRUE)
statistic(data[boot_samples])
}) -> boot_statistic
boot_statistic
}
bootstrap(data, mean)
sd(bootstrap(data, mean))
sd(bootsrap(data, function(x){quantile(x, 0.9)}))
sd(bootstrap(data, function(x){quantile(x, 0.9)}))
1.96*sd(boot_statistic)
data(StudentSurvey)
View(StudentSurvey)
train <- StudentSurvey
library(dplyr)
names(train)
train %>% group_by(Gender) %>% summarize(mean(GPA))
train %>% group_by(Gender) %>% summarize(mean(MathSAT))
View(train)
bootstrap(train$MAthSAT[train$Gender == F], mean)
bootstrap(train$MAthSAT[train$Gender == F], function(x) mean(x, na.rm = TRUE))
train$MAthSAT[train$Gender == F]
bootstrap(train$MAthSAT[train$Gender == "F"], function(x) mean(x, na.rm = TRUE))
train$MAthSAT[train$Gender == "F"]
train$MAthSAT
bootstrap(train$MathSAT[train$Gender == "F"], function(x) mean(x, na.rm = TRUE))
bootstrap(train$MathSAT[train$Gender == "F"],
function(x) mean(x, na.rm = TRUE)) -> boot_statistic
train %>% group_by(Gender) %>% summarize(mean(MathSAT))
2*sd(boot_statistic)
2*sd(boot_statistic)
bootstrap(train$MathSAT[train$Gender == "F"], mean)
bootstrap(train$MathSAT[train$Gender == "F"], mean) -> boot_statistic_f
2*sd(boot_statistic_m)
bootstrap(train$MathSAT[train$Gender == "F"], mean) -> boot_statistic_m
2*sd(boot_statistic_m)
2*sd(boot_statistic_f)
train %>% group_by(Gender) %>% summarize(mean(MathSAT))
t.test(train$MathSAT[train$Gender == "F"],
train$MathSAT[train$Gender == "M"])
male <- train$MathSAT[train$Gender == "M"]
female <- train$MathSAT[train$Gender == "F"]
sample(length(male), replace = TRUE)
male <- train$MathSAT[train$Gender == "M"]
female <- train$MathSAT[train$Gender == "F"]
replicate(1000, {
boot_samples_m <- sample(length(male), replace = TRUE)
boot_samples_f <- sample(length(female), replace = TRUE)
mean(male[boot_samples_m] - mean(female[boot_smales_n]))
}) -> boot_statistic
male <- train$MathSAT[train$Gender == "M"]
female <- train$MathSAT[train$Gender == "F"]
replicate(1000, {
boot_samples_m <- sample(length(male), replace = TRUE)
boot_samples_f <- sample(length(female), replace = TRUE)
mean(male[boot_samples_m] - mean(female[boot_samples_n]))
}) -> boot_statistic
male <- train$MathSAT[train$Gender == "M"]
female <- train$MathSAT[train$Gender == "F"]
replicate(1000, {
boot_samples_m <- sample(length(male), replace = TRUE)
boot_samples_f <- sample(length(female), replace = TRUE)
mean(male[boot_samples_m] - mean(female[boot_samples_f]))
}) -> boot_statistic
hist(boot_statistic)
mean(boot_statistic <0)
t.test(train$MathSAT[train$Gender == "F"],
train$MathSAT[train$Gender == "M"])
intervl <- mean(boot_statistic) + c(-2,2)*sd(boot_statistic))
interval <- mean(boot_statistic) + c(-2,2)*sd(boot_statistic))
mean(boot_statistic)
sd(boot_statistic)
interval <- mean(boot_statistic) + c(-2,2)*sd(boot_statistic))
interval <- mean(boot_statistic) + c(-2,2)*sd(boot_statistic)
interval
t.test(train$MathSAT[train$Gender == "F"],
train$MathSAT[train$Gender == "M"])
mean(boot_statistic < 0) #probability the two come from the same population
2*mean(boot_statistic < 0) #probability the two come from the same population
data <- cbind(male, female)
data <- c(male, female)
len <- length(male)
length(data)
sample(length(data))
unique(sample(length(data)))
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
replicate(1000, {
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
})
}) -> permutation_stat
replicate(1000, {
permutation <- sample(length(data))
data <- data[permutation]
mean(data[1:len]) - mean(data[-(1:len)])
}) -> permutation_stat
hist(permutation_stat)
hline(mean(male)- mean(female))
abine(mean(male)- mean(female))
abline(mean(male)- mean(female))
abline(v = mean(male)- mean(female))
mean(permutation_stat >  mean(male)- mean(female))
mean(permutation_stat >  mean(male)- mean(female)) *2
dir()
library(dplyr)
library(tidyr)
library(plotly)
counties <- read.csv("county_facts.csv")
primary <- read.csv("primary_results.csv")
primary %>% filter(party == "Democrat") -> primary
primary$votes <- NULL
primary %>% spread(candidate, fraction_votes) -> dem_votes
dem_votes$`Martin O'Malley` <- NULL
dem_votes$` No Preference` <- NULL
dem_votes$` Uncommitted` <- NULL
primary %>% group_by(fips) %>% summarize(sum(votes)) -> num_votes
#USE THIS to remove counties that have few votes.
dem_votes$winner <- "Hillary"
dem_votes$winner[dem_votes$`Bernie Sanders` > dem_votes$`Hillary Clinton`] <- "Bernie"
dem_votes <- inner_join(dem_votes, counties, by = "fips")
train <-dem_votes[,c(8,11:dim(dem_votes)[2])] #winner plus different demographics.
train$winner <- as.factor(train$winner)
ggplot(train, aes(x = EDU635213, y = log(1 + RHI225214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
train$hs_bin <- cut(train$EDU635213, breaks = 30)
pplot(hs_bin) + coord_flip() + geom_bar() #striking.
pplot <- function(x) {
x <- substitute(x)
ggplot(data = train, aes_q(x = x, fill = substitute(winner))) +
geom_bar(stat = "count", position = "fill", width = 0.8) +
scale_fill_brewer(palette = "Set1")
}
pplot(hs_bin) + coord_flip() + geom_bar() #striking.
pplot(hs_bin) + coord_flip() + geom_bar() +
labs(title = "Winner by Percentage of People With High School Diploma")
?labs
pplot(hs_bin) + coord_flip() + geom_bar() +
labs(title = "Winner by Percentage of People With High School Diploma",
xlab = "Percentage with HS Diploma")
pplot(black_bin) + geom_bar() + coord_flip()
pplot(hs_bin) + coord_flip() + geom_bar() +
labs(title = "Winner by Percentage of People With High School Diploma",
xlab = "Percentage with HS Diploma")
?labs
pplot(hs_bin) + coord_flip() + geom_bar() +
labs(title = "Winner by Percentage of People With High School Diploma",
xlab = "Percentage with HS Diploma")
pplot(hs_bin) + coord_flip() +
labs(title = "Winner by Percentage of People With High School Diploma",
xlab = "Percentage with HS Diploma")
pplot(hs_bin) + coord_flip() + geom_bar() +
labs(title = "Winner by Percentage of People With High School Diploma",
xlab = "Percentage with HS Diploma")
pplot(hs_bin) + coord_flip() + geom_bar() +
labs(title = "Winner by Percentage of People With High School Diploma",
xlab = "Percentage with HS Diploma")
pplot(hs_bin) + coord_flip()  +
labs(title = "Winner by Percentage of People With High School Diploma",
xlab = "Percentage with HS Diploma")
pplot(hs_bin) + coord_flip()  + geom_bar()+
labs(title = "Winner by Percentage of People With High School Diploma",
xlab = "Percentage with HS Diploma")
ggplot(train, aes(x = EDU635213, y = log(1 + RHI225214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
X <- as.matrix(train[,2:52])
y = 1*(train$winner == "Hillary")
xgb.cv(data = X, label = y, nfold = 10, nrounds = 200,
objective = "binary:logistic",
metrics = c("error", "auc")) -> cv.error
plot(cv.error$test.error.mean)
plot(cv.error$test.auc.mean)
max(cv.error$test.auc.mean)
model_xgb <- xgboost(data = X, label = y,nrounds = 200,
objective = "binary:logistic")
xgb.importance(feature_names = colnames(X), model = model_xgb) -> xgb_importance
xgb_importance$Feature[1:10] ->important_features
View(xgb_importance)
library(dplyr)
library(tidyr)
library(plotly)
counties <- read.csv("county_facts.csv")
primary <- read.csv("primary_results.csv")
primary %>% filter(party == "Democrat") -> primary
primary$votes <- NULL
primary %>% spread(candidate, fraction_votes) -> dem_votes
dem_votes$`Martin O'Malley` <- NULL
dem_votes$` No Preference` <- NULL
dem_votes$` Uncommitted` <- NULL
primary %>% group_by(fips) %>% summarize(sum(votes)) -> num_votes
#USE THIS to remove counties that have few votes.
dem_votes$winner <- "Hillary"
dem_votes$winner[dem_votes$`Bernie Sanders` > dem_votes$`Hillary Clinton`] <- "Bernie"
dem_votes <- inner_join(dem_votes, counties, by = "fips")
train <-dem_votes[,c(8,11:dim(dem_votes)[2])] #winner plus different demographics.
train$winner <- as.factor(train$winner)
#models:
library(ranger)
library(randomForest)
library(xgboost)
library(gbm)
#very nice separation:
ggplot(train, aes(x = EDU635213, y = log(1 + RHI225214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
ggplot(train, aes(x = EDU635213, y = RHI225214)) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
ggplot(train, aes(x = EDU635213, y = log10(RHI225214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
ggplot(train, aes(x = EDU635213, y = log10(1 + RHI225214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
ggplot(train, aes(x = log(100 - EDU635213), y = log(1 + RHI225214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
ggplot(train, aes(x = log(60 - EDU635213), y = log(1 + RHI225214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
ggplot(train, aes(x = EDU635213, y = log(1 + RHI225214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
ggplot(train, aes(x = EDU635213, y = log(1 + RHI225214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1") +
xlim(c(60, 100))
ggplot(train, aes(x = AGE775214, y = RHI325214)) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
ggplot(train, aes(x = AGE775214, y = log(1 + RHI325214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
ggplot(train, aes(x = log(1 + AGE775214), y = log(1 + RHI325214))) +
geom_point(aes(color = winner), alpha = 0.8) +
scale_color_brewer(palette = "Set1")
2+2+2+2+2+2+2+2+2+2+2+2
hist(train$EDU635213)
train$hs_bin <- cut(train$EDU635213, breaks = 30)
train$black_bin <- cut(sqrt(train$RHI225214), breaks = 30) #take sqrt here to visualize better
pplot <- function(x) {
x <- substitute(x)
ggplot(data = train, aes_q(x = x, fill = substitute(winner))) +
geom_bar(stat = "count", position = "fill", width = 0.8) +
scale_fill_brewer(palette = "Set1")
}
pplot(hs_bin) + coord_flip()  + geom_bar()+
labs(title = "Winner by Percentage of People With High School Diploma",
xlab = "Percentage with HS Diploma")
pplot(hs_bin) + coord_flip()  + geom_bar(position = "fill")+
labs(title = "Winner by Percentage of People With High School Diploma",
xlab = "Percentage with HS Diploma")
#XGBoost:
X <- as.matrix(train[,2:52])
y = 1*(train$winner == "Hillary")
xgb.cv(data = X, label = y, nfold = 10, nrounds = 200,
objective = "binary:logistic",
metrics = c("error", "auc")) -> cv.error
kable(head(train, 3))
library(ISLR)
library(ggplot2)
library(knitr)
train = Wage
kable(head(train, 3))
ggplot(train, aes(x = wage, fill = education)) +
geom_histogram(bins = 40) +
scale_fill_brewer(palette = "Set1")
ggplot(train, aes(x = wage, fill = education)) +
geom_histogram(bins = 40)
ggplot(train, aes(x = wage, fill = education)) +
geom_histogram(bins = 30)
ggplot(train, aes(x = wage, fill = education)) +
geom_histogram(bins = 25)
ggplot(train, aes(x = wage, fill = education)) +
geom_histogram(bins = 20)
ggplot(train, aes(x = wage, fill = education)) +
geom_histogram(bins = 25)
ggplot(train, aes(x = wage, fill = education)) +
geom_histogram(bins = 25) +
scale_fill_brewer(palette = "Set1")
ggplot(train, aes(x = Sepal.Length, y = Petal.Length)) + geom_point(aes(color = Species))
train = iris
ggplot(train, aes(x = Sepal.Length, y = Petal.Length)) + geom_point(aes(color = Species))
names(train)
plot_ly(x = Sepal.Length, y = Sepal.Width, z = Petal.Length)
plot_ly(x = Sepal.Length, y = Sepal.Width, z = Petal.Length, data = train)
plot_ly(x = Sepal.Length, y = Sepal.Width, z = Petal.Length, data = train, type = type = "scatter3d", mode = "markers")
plot_ly(x = Sepal.Length, y = Sepal.Width, z = Petal.Length, data = train, color = Species,type = "scatter3d", mode = "markers")
